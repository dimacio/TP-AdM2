# Operaciones de Aprendizaje de M谩quina I (CEIA-MLOps1)

**Profesores:**  
Facundo Adri谩n Lucianna - facundolucianna@gmail.com

## Integrantes

- a1721 Dimas Ignacio Torres (dimaciodimacio@gmail.com)
- a1726 Joaqu铆n Mat铆as Mestanza (joa.mestanza@gmail.com)
- a1714 Ramiro Andr茅s Feichubuinm (ra.feichu@gmail.com)

## Descripci贸n del Proyecto

Este proyecto desarrolla un pipeline completo de machine learning para la predicci贸n de precios de apertura de acciones, utilizando datos hist贸ricos descargados autom谩ticamente desde Yahoo Finance. El flujo de trabajo est谩 completamente orquestado con Airflow, permitiendo la automatizaci贸n de tareas de extracci贸n, procesamiento, entrenamiento y evaluaci贸n de modelos.

El modelo principal es una red neuronal LSTM, entrenada para predecir el precio de apertura de una acci贸n (por defecto NVDA), aunque es f谩cilmente configurable para otros activos. El tracking de experimentos y gesti贸n de modelos se realiza con MLflow, mientras que los artefactos y modelos entrenados se almacenan en MinIO, compatible con S3.

El sistema expone una API REST desarrollada en FastAPI, que permite realizar predicciones en tiempo real utilizando el modelo m谩s reciente. Adem谩s, se provee una interfaz web en Streamlit para la visualizaci贸n de resultados y consumo de predicciones de manera sencilla e interactiva.

Toda la infraestructura se despliega mediante Docker Compose, integrando servicios como MLflow, MinIO, PostgreSQL, Airflow, FastAPI, Redis y Streamlit, facilitando la reproducibilidad y escalabilidad del entorno de desarrollo y producci贸n.

## Como correr el proyecto

Estando en root correr:

```
docker-compose up --build
```

## Rutas 煤tiles

- **MLflow:** [http://localhost:5001](http://localhost:5001)
- **MinIO (Bucket):** [http://localhost:9001](http://localhost:9001)
- **Airflow:** [http://localhost:8080](http://localhost:8080)
- **Airflow API Docs:** [http://localhost:8080/api/v1/ui/](http://localhost:8080/api/v1/ui/)
- **FastAPI:** [http://localhost:8000](http://localhost:8000)
- **Streamlit:** [http://localhost:8501](http://localhost:8501)

## Arquitectura de Contenedores

El proyecto utiliza Docker Compose para orquestar los siguientes servicios:

- **MLflow**: Tracking de experimentos y almacenamiento de modelos ([http://localhost:5001](http://localhost:5001))
- **MinIO (Bucket)**: Almacenamiento de artefactos S3 compatible ([http://localhost:9001](http://localhost:9001))
- **PostgreSQL (MLflow y Airflow)**: Bases de datos para MLflow y Airflow
- **Airflow**: Orquestador de pipelines de entrenamiento y evaluaci贸n ([http://localhost:8080](http://localhost:8080))
- **FastAPI**: API REST para predicci贸n de precios ([http://localhost:8000](http://localhost:8000))
- **Redis**: Almacenamiento temporal de credenciales para autenticaci贸n
- **Streamlit**: Interfaz web para visualizaci贸n y consumo de predicciones ([http://localhost:8501](http://localhost:8501))

### Diagrama de servicios

```mermaid
graph TD
    Usuario --> Streamlit
    Streamlit --> FastAPI
    FastAPI --> MLflow
    FastAPI --> MinIO
    FastAPI -.-> Redis
    FastAPI -.-> Airflow
    MLflow --> MinIO
    MLflow --> PostgreSQL
    Airflow --> MLflow
    Airflow --> MinIO
    Airflow --> PostgreSQL
```

## Resumen del trabajo realizado

- Se implement贸 un DAG en Airflow que posee dos partes: entrenamiento y evaluaci贸n.
  Este DAG interact煤a con MLFLow para registrar datos del experimento y se asegura de que se guarden los archivos necesarios del modelo para luego realizar una inferencia. Los datos son guardados por medio de un Bucket MinIO.

  Estos entrenamientos en Airflow tienen la posibilidad de ser scheduleados, es decir que podriamos correr el entrenamiento diariamente (despu茅s de que la cotizaci贸n del d铆a ya se sabe).

- Se implement贸 una API ([README ](./api/README.md)) con FastAPI con los endpoints:

  - `/login`: Autenticaci贸n con Airflow (default: `admin admin`).
    Si la autenticaci贸n es exitosa, el endpoint devuelve un JWT Token el cual act煤a como llave en una base de Redis cuyo valor son las credenciales (con TTL de 60 minutos).
    De esta manera, al obtener el token uno puede seguir seguir haciendo peticiones a Airflow por medio de esta API.

  - `/trigger-new-dag-run`: Apuntamos a un dag en espec铆fico para correr en airflow.

  - `/predict-sample`: Llamamos a nuestro mejor entrenamiento seg煤n fecha, la m茅trica y el nombre de la acci贸n seleccionada.

- Streamlit para observar los datos hist贸ricos y de nuestras predicciones.

## Mejoras aplicables en un entorno profesional

- Manejo de dependencias. Actualmente las dependencias no tienen versi贸n fija, por lo cual siempre consiguen el `latest` que sea compatible con las otras que ya poseemos. Esto no es ideal ya que podr铆a llegar a romper el proyecto.

- Crear usuarios con roles separados para automatizaciones.
- Cambiar credenciales de usuario admin por defecto.
- Utilizar Redis para servir los datos de Yahoo Finance (esto sirve tanto para los entrenamientos como para los usuarios).
